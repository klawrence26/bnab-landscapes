{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import dok_matrix, csr_matrix\n",
    "from sklearn.preprocessing import normalize\n",
    "import networkx as nx\n",
    "import itertools\n",
    "from itertools import islice\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.patches import Patch\n",
    "import scipy as sp\n",
    "import math\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "\n",
    "\n",
    "\n",
    "mpl.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams.update({'font.size': 7,'axes.linewidth':0.5,\n",
    "                     'xtick.major.size':2,'xtick.major.width':0.5,\n",
    "                    'ytick.major.size':2,'ytick.major.width':0.5})\n",
    "plt.rcParams.update({'mathtext.default':  'regular' })\n",
    "\n",
    "\n",
    "colorH1, colorH3, colorFluB, colorH9 = \"#E8735C\", \"#72C2A6\", \"#5482A7\", \"#663399\"\n",
    "\n",
    "\n",
    "#### antibody choice ####\n",
    "#antibody = \"9114\"\n",
    "antibody = \"6261\" \n",
    "\n",
    "antigens = [\"H1\", \"H3\", \"FluB\"] if antibody == \"9114\" else [\"H1\", \"H9\"]\n",
    "L = (16 if antibody == \"9114\" else 11)\n",
    "sequences_int = range(2**L)\n",
    "\n",
    "\n",
    "#### selection model choice ####\n",
    "#model = 'strong'\n",
    "#model = 'moderate'\n",
    "model = 'weak'\n",
    "\n",
    "\n",
    "if model == 'moderate':\n",
    "    N = 1000\n",
    "    gamma = 1.0\n",
    "elif model == 'weak':\n",
    "    N = 20\n",
    "    gamma = 0.5\n",
    "\n",
    "Nbootstrap=10\n",
    "\n",
    "\n",
    "# define some functions\n",
    "def mutation(s, ii, L):\n",
    "    \"\"\" Return the sequence (in int format) with base s,\n",
    "        with a somatic mutation at pos ii \"\"\"\n",
    "    return s | 2**(L-1-ii)\n",
    "\n",
    "def nb_mutation(s):\n",
    "    \"\"\" Number of mutations in variant s \"\"\"\n",
    "    return bin(s).count(\"1\")\n",
    "\n",
    "def reachable(s, L):\n",
    "    return [(s | 2**ii) for ii in range(L) if (s | 2**ii) > s]\n",
    "\n",
    "def k_shortest_paths(G, source, target, k, weight=None):\n",
    "    return list(\n",
    "        islice(nx.shortest_simple_paths(G, source, target, weight=weight), k)\n",
    "    )\n",
    "def truncate_colormap(cmap, minval=0.0, maxval=1.0, n=100):\n",
    "    new_cmap = colors.LinearSegmentedColormap.from_list(\n",
    "        'trunc({n},{a:.2f},{b:.2f})'.format(n=cmap.name, a=minval, b=maxval),\n",
    "        cmap(np.linspace(minval, maxval, n)))\n",
    "    return new_cmap\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "131\n"
     ]
    }
   ],
   "source": [
    "# read dataframe\n",
    "if antibody == \"9114\":\n",
    "    df = pd.read_csv(\"../../CR9114/Kd_meanbin/kd_processed/20210427_HA_unadj_fil_merg.csv\",\n",
    "                     dtype={\"variant\":\"str\"})\n",
    "    df = df.rename(columns={\"h1_mean\": \"H1_log10Kd\", \"h3_mean\": \"H3_log10Kd\", \"fluB_mean\": \"FluB_log10Kd\",\n",
    "                        \"h1_sem\": \"H1_stelog10Kd\", \"h3_sem\": \"H3_stelog10Kd\", \"fluB_sem\": \"FluB_stelog10Kd\"})\n",
    "else:\n",
    "    df = pd.read_csv(\"../../CR6261/Kd_meanbin/kd_processed/20210323_6261_HA_unadj_fil_merg.csv\",\n",
    "                     dtype={\"variant\":\"str\"})\n",
    "    df = df.rename(columns={\"h1_mean\": \"H1_log10Kd\", \"h9_mean\": \"H9_log10Kd\",\n",
    "                        \"h1_sem\": \"H1_stelog10Kd\", \"h9_sem\": \"H9_stelog10Kd\"})\n",
    "\n",
    "# convert genotypes to integers and sort accordingly    \n",
    "df[\"variant_int\"] = df.variant.apply(lambda x: int(x, 2))\n",
    "df = df.set_index(\"variant_int\").reindex(range(0, 2**L)).reset_index()\n",
    "\n",
    "for ii in range(L):\n",
    "    df[f\"mutation_{ii+1}\"] = df.variant.str[ii] == '1'\n",
    "    \n",
    "    \n",
    "# get average Kd for mixed scenarios    \n",
    "df['mixed_log10Kd'] = df[[f\"{a}_log10Kd\" for a in antigens]].mean(axis=1)\n",
    "\n",
    "print(len(df))\n",
    "print(len(df.loc[df['mixed_log10Kd'].isna()]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define selection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixation_probability_moderate(fitness_s,fitness_t,Npop,gamma):\n",
    "    if np.isnan(fitness_s) or np.isnan(fitness_t):\n",
    "        pval = 0.0\n",
    "    else:\n",
    "        delta = fitness_t - fitness_s\n",
    "        if delta == 0.0:\n",
    "            pval = 1.0/Npop\n",
    "        else:\n",
    "            pval = ((1 - np.exp(-gamma*delta))/(1 - np.exp(-Npop*gamma*delta)))\n",
    "    return pval\n",
    "    \n",
    "    \n",
    "def fixation_probability_binary(s,fitness_s,fitness_t):\n",
    "    if nb_mutation(s) == 0 and antibody == '6261':\n",
    "        pval = 1.0\n",
    "    elif np.isnan(fitness_s) or np.isnan(fitness_t):\n",
    "        pval = 0.0\n",
    "    elif (fitness_t-fitness_s) > 0:\n",
    "        pval = 1.0\n",
    "    else:\n",
    "        pval = 0.0\n",
    "    return pval\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate transition probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36b463d181154521b59025d0579d1d71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Nbootstrap = 10\n",
    "\n",
    "# Create the transition matrix between variant, depending on context\n",
    "pmut = {}\n",
    "for nb in tqdm(range(Nbootstrap)):\n",
    "    for ag in antigens + [\"mixed\"]:\n",
    "        pmut[ag, nb] = dok_matrix((2**L, 2**L), dtype=np.float64)\n",
    "        if ag != \"mixed\":\n",
    "            fitnesses = np.random.normal(\n",
    "                        (df[f\"{ag}_log10Kd\"]).values.astype('float32'),\n",
    "                        (df[f\"{ag}_stelog10Kd\"]).values.astype('float32'))\n",
    "        else:\n",
    "            fitnesses = sum([np.random.normal(\n",
    "                        (df[f\"{aa}_log10Kd\"]).values.astype('float32'),\n",
    "                        (df[f\"{aa}_stelog10Kd\"]).values.astype('float32')) for aa in antigens])/len(antigens)\n",
    "        \n",
    "        for s in sequences_int:\n",
    "            tot = 0\n",
    "            for t in reachable(s, L):\n",
    "                if model == 'strong':\n",
    "                    pmut[ag, nb][s, t] = fixation_probability_binary(s,fitnesses[s],fitnesses[t])\n",
    "                else:  \n",
    "                    pmut[ag, nb][s, t] = fixation_probability_moderate(fitnesses[s],fitnesses[t],N,gamma)\n",
    "\n",
    "        ### change format for something that can deal with multiplications\n",
    "        pmut[ag, nb].tocsr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### compute for every context\n",
    "all_contexts = set()\n",
    "for order in itertools.permutations(antigens):\n",
    "    for a in itertools.combinations_with_replacement(order, L):\n",
    "        all_contexts.add(a)\n",
    "all_contexts.add(tuple([\"mixed\"]*L))\n",
    "\n",
    "proba = defaultdict(list)\n",
    "for context in tqdm(all_contexts):\n",
    "    for nb in range(Nbootstrap):\n",
    "        P = pmut[context[0], nb][0, :] # start vector\n",
    "        for c in context[1:]:\n",
    "            P = P@pmut[c, nb]\n",
    "        proba[context] += [P[0, 2**L - 1]]\n",
    "\n",
    "# write data to file\n",
    "with open('data/likelihoods_'+antibody+'_'+model+'.csv','w') as writefile:\n",
    "    proba_writer = csv.writer(writefile)\n",
    "    for key in proba.keys():\n",
    "        list_to_write = [x for x in key] + [x for x in proba[key]]\n",
    "        proba_writer.writerow(list_to_write)\n",
    "    writefile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb578c2522174cb7b9020a9d94dd4807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.0001315168987432247 5.003150385837092e-06\n"
     ]
    }
   ],
   "source": [
    "# draw random contexts\n",
    "\n",
    "num_random_contexts = 1000\n",
    "random_contexts = []\n",
    "for i in range(num_random_contexts):\n",
    "    random_contexts.append(np.random.choice(antigens,size=L))\n",
    "        \n",
    "proba_random = np.zeros((num_random_contexts,Nbootstrap))\n",
    "for i in tqdm(range(num_random_contexts)):\n",
    "    context = random_contexts[i]\n",
    "    for nb in range(Nbootstrap):\n",
    "        P = pmut[context[0], nb][0, :] # start vector\n",
    "        for c in context[1:]:\n",
    "            P = P@pmut[c, nb]\n",
    "        proba_random[i,nb] += [P[0, 2**L - 1]]\n",
    "        \n",
    "proba_random_mean = np.mean(np.mean(proba_random,axis=1),axis=0)\n",
    "proba_random_std = np.std(np.std(proba_random,axis=1))\n",
    "print(proba_random_mean,proba_random_std)\n",
    "\n",
    "# write data to file\n",
    "with open('data/likelihoods_'+antibody+'_'+model+'_random.csv','w') as writefile:\n",
    "    proba_writer = csv.writer(writefile)\n",
    "    for i in range(len(proba_random)):\n",
    "        list_to_write = [x for x in random_contexts[i]] + [x for x in proba_random[i]]\n",
    "        proba_writer.writerow(list_to_write)\n",
    "    writefile.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read probabilities from file for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read likelihoods from file\n",
    "\n",
    "\n",
    "proba_from_file = defaultdict(list)\n",
    "with open('data/likelihoods_'+antibody+'_'+model+'.csv','r') as readfile:\n",
    "    proba_reader = csv.reader(readfile)\n",
    "    for row in proba_reader:\n",
    "        key = tuple(row[:L])\n",
    "        value = [float(x) for x in row[L:]]\n",
    "        proba_from_file[key] = value\n",
    "    readfile.close()\n",
    "\n",
    "if antibody == '6261' and model == 'weak2':\n",
    "    num_random_contexts = 100\n",
    "else:\n",
    "    num_random_contexts = 1000\n",
    "proba_random_from_file = np.zeros((num_random_contexts,Nbootstrap))\n",
    "contexts_random_from_file = []\n",
    "with open('data/likelihoods_'+antibody+'_'+model+'_random.csv','r') as readfile:\n",
    "    proba_reader = csv.reader(readfile)\n",
    "    i = 0\n",
    "    for row in proba_reader:\n",
    "        key = tuple(row[:L])\n",
    "        contexts_random_from_file.append(key)\n",
    "        value = [float(x) for x in row[L:]]   \n",
    "        proba_random_from_file[i] = value\n",
    "        i += 1\n",
    "    readfile.close()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39916800\n",
      "0.0021005090588423923\n",
      "0.0004760203310062592\n"
     ]
    }
   ],
   "source": [
    "print(math.factorial(L))\n",
    "print(np.mean(proba_from_file[tuple([\"H1\"]*L)])/math.factorial(L))\n",
    "print(np.std(proba_from_file[tuple([\"H1\"]*L)],ddof=1)/math.factorial(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5C,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a subset of contexts for strong selection model\n",
    "print(model)\n",
    "# plot for strong selection (binary) model\n",
    "if model != 'strong':\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# select contexts we want to plot\n",
    "\n",
    "if antibody == '9114':\n",
    "    constant_scenarios = [tuple([\"H1\"]*L),tuple([\"H3\"]*L),tuple([\"FluB\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "elif antibody == '6261':\n",
    "    constant_scenarios = [tuple([\"H1\"]*L),tuple([\"H9\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "\n",
    "    \n",
    "# sort other scenarios by likelihood\n",
    "scenarios_sorted = [k for k, v in sorted(proba_from_file.items(), key=lambda item: -(np.mean([a for a in item[1]]))) if not all([l == k[0] for l in k])]\n",
    "#print(scenarios_sorted)\n",
    "if antibody == '9114':\n",
    "    # get best examples of each orderings\n",
    "    other_orderings = []\n",
    "    others = []\n",
    "    for i in range(len(scenarios_sorted)):\n",
    "        scenario_collapsed = list(OrderedDict.fromkeys(scenarios_sorted[i]))\n",
    "        if scenario_collapsed not in other_orderings:\n",
    "            other_orderings.append(scenario_collapsed)\n",
    "            others.append(scenarios_sorted[i])\n",
    "\n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + others[:8])[::-1])\n",
    "    print(keys)\n",
    "\n",
    "elif antibody == '6261':\n",
    "    # get best examples of each orderings\n",
    "    other_orderings = []\n",
    "    others = []\n",
    "    for i in range(len(scenarios_sorted)):\n",
    "        scenario_collapsed = list(OrderedDict.fromkeys(scenarios_sorted[i]))\n",
    "        if scenario_collapsed not in other_orderings:\n",
    "            other_orderings.append(scenario_collapsed)\n",
    "            others.append(scenarios_sorted[i])\n",
    "\n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + others)[::-1])\n",
    "    print(keys)\n",
    "        \n",
    "likelihoods, err_likelihoods = [], []\n",
    "for k in keys:\n",
    "    if \"white\" in k:\n",
    "        likelihoods += [np.nan]\n",
    "        err_likelihoods += [np.nan]\n",
    "    elif \"random\" in k:\n",
    "        if np.median(proba_random_from_file[:,0]) == 0.0:\n",
    "            likelihoods += [np.nan]\n",
    "            err_likelihoods += [np.nan]\n",
    "        else:\n",
    "#             likelihoods += [np.mean(np.mean(np.log10(proba_random_from_file),axis=1),axis=0)]\n",
    "#             err_likelihoods += [np.std(np.std(proba_random_from_file,axis=1,ddof=1)/np.mean(proba_random_from_file,axis=1),ddof=1) ]\n",
    "\n",
    "            likelihoods += [np.mean(np.mean(proba_random_from_file,axis=1),axis=0)]\n",
    "            err_likelihoods += [np.std(np.std(proba_random_from_file,axis=1,ddof=1),axis=0,ddof=1) ]\n",
    "\n",
    "    elif np.mean(proba_from_file[k]) > 0.0:\n",
    "#         likelihoods += [np.mean(np.log10(proba_from_file[k]))]\n",
    "#         err_likelihoods += [np.std(proba_from_file[k],ddof=1)/np.mean(proba_from_file[k])]\n",
    "        \n",
    "        likelihoods += [np.mean(proba_from_file[k])]\n",
    "        err_likelihoods += [np.std(proba_from_file[k],ddof=1)]\n",
    "\n",
    "    elif np.mean(proba_from_file[k]) == 0.0:\n",
    "        likelihoods += [np.nan]\n",
    "        err_likelihoods += [np.nan]\n",
    "        \n",
    "        \n",
    "likelihoods = np.array(likelihoods)\n",
    "err_likelihoods = np.array(err_likelihoods)\n",
    "print(likelihoods)\n",
    "    \n",
    "val = np.zeros((5*L, 5*len(keys)))\n",
    "for ii, key in enumerate(keys):\n",
    "    for jj, a in enumerate(key):\n",
    "        val[5*jj:5*(jj+1), 5*ii:5*(ii+1)] = {\"H1\":1, \"H3\":2, \"FluB\":3, \"H9\":4, \"\":0, \"white\":-1, \"random\":-2, \"mixed\":-2}[a]\n",
    "\n",
    "if antibody == '6261':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.3,0.5))\n",
    "    gs = fig.add_gridspec(1,7)\n",
    "    ax0 = fig.add_subplot(gs[0,0:4])\n",
    "    ax = fig.add_subplot(gs[0,4:], sharey=ax0)\n",
    "\n",
    "elif antibody == '9114':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.8,0.9))\n",
    "    gs = fig.add_gridspec(1,5)\n",
    "    ax0 = fig.add_subplot(gs[0,0:3])\n",
    "    ax = fig.add_subplot(gs[0,3:], sharey=ax0)\n",
    "\n",
    "# Turn off tick labels\n",
    "ax0.set_yticks([])\n",
    "ax0.set_xticks(range(0,5*(L+1),5))\n",
    "ax0.set_xticklabels([])\n",
    "ax0.spines['top'].set_color('white')\n",
    "#ax0.spines['bottom'].set_color('white')\n",
    "ax0.spines['right'].set_color('white')\n",
    "ax0.spines['left'].set_color('white')\n",
    "\n",
    "colorH1, colorH3, colorFluB, colorH9 = \"#E8735C\", \"#72C2A6\", \"#5482A7\", \"#663399\"\n",
    "\n",
    "pal = sns.color_palette()\n",
    "colors = [colorH1, 'white', 'xkcd:light grey', colorH1, colorH3, colorFluB, colorH9]\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "ax0.imshow(val.transpose(), interpolation='none', vmin=-2, vmax=4, cmap=cmap)\n",
    "mpl.rcParams['hatch.linewidth'] = 5 # previous pdf hatch linewidth\n",
    "mpl.rcParams['hatch.color'] = colorH3 # previous pdf hatch linewidth\n",
    "\n",
    "\n",
    "if antibody == \"9114\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 4\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH3]))\n",
    "    \n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 > 7\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorFluB]))\n",
    "\n",
    "if antibody == \"6261\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 5\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH9]))\n",
    "\n",
    "\n",
    "\n",
    "ax0.set_aspect('auto')\n",
    "for ii in range((val.shape[1]//5+1)):\n",
    "    ax0.axhline(5*ii-0.3, color=\"white\", alpha=1, lw=1)\n",
    "    #ax0.plot([0,5*L],[5*ii-.9,5*ii-.9],color=\"white\", alpha=1, lw=1)\n",
    "    #ax0.plot([0,5*L],[5*ii-.1,5*ii-.1],color=\"white\", alpha=1, lw=1)\n",
    "\n",
    "ax0.set_ylim(-1.5, val.shape[1]-1.5)\n",
    "ax0.set_xlim([0,5*L])\n",
    "#ax0.set_xlabel(\"Context\")\n",
    "\n",
    "# max_loglik = np.nanmax(np.log(likelihoods))\n",
    "# min_loglik = np.nanmin(np.log(likelihoods))\n",
    "value_displayed = likelihoods #(-min_loglik + np.log(likelihoods))/(max_loglik - min_loglik)*0.8 + 0.1\n",
    "err_values = np.nan_to_num(err_likelihoods, 0)#/(max_loglik - min_loglik)*0.8, 0)\n",
    "\n",
    "#print(err_values)\n",
    "\n",
    "ax.barh(width=value_displayed+40,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5), height=4.5, left=-40,\n",
    "        color = 'grey' )\n",
    "        #color=[\"#7da6c2\", \"#c5e7ff\"]*(len(likelihoods)//2))\n",
    "#ax.invert_xaxis()\n",
    "ax.errorbar(x=value_displayed,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5),\n",
    "            xerr=err_values, color=\"k\", markersize=10, linestyle='', elinewidth=0.5, ecolor='k')\n",
    "\n",
    "#ax.set_xlabel(\"Context log-likelihood\")\n",
    "\n",
    "ax.set_ylim(-1, val.shape[1]+1)\n",
    "\n",
    "if antibody == \"9114\":\n",
    "    ax.set_xlim(0,2.2e8)\n",
    "    ax.set_xticks([0,1e8,2e8])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "elif antibody == \"6261\":\n",
    "    ax.set_xlim(0,2.4e5)\n",
    "    ax.set_xticks([0,1e5,2e5])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "plt.savefig(f\"images/context_likelihood_{antibody}_{model}_subset.pdf\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5--Figure Supplement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal: ('H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H1', 'H3', 'H3', 'H3', 'H3', 'H3', 'H3', 'H3', 'H3')\n",
      "[ 60248.9     60766.8     80776.4     83845.6     89109.     101328.\n",
      " 102222.8    107165.2    107705.4    107841.     110838.8    135191.7\n",
      " 145324.1    162012.5    175671.8    181928.8    186372.7    188468.9\n",
      "         nan  54340.2     83845.6    118053.6977]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-23-fc16f5514847>:167: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  plt.subplots_adjust(hspace=0.3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 160x200 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for strong selection (binary) model\n",
    "if model != 'strong':\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# select contexts we want to plot\n",
    "\n",
    "if antibody == '9114':\n",
    "    constant_scenarios = [tuple([\"random\"]*L),\n",
    "                      tuple([\"H1\"]*L),tuple([\"H3\"]*L),tuple([\"FluB\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "elif antibody == '6261':\n",
    "    constant_scenarios = [tuple([\"random\"]*L),\n",
    "                      tuple([\"H1\"]*L),tuple([\"H9\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "\n",
    "    \n",
    "# sort other scenarios by likelihood\n",
    "scenarios_sorted = [k for k, v in sorted(proba_from_file.items(), key=lambda item: -(np.mean([a for a in item[1]]))) if not all([l == k[0] for l in k])]\n",
    "#print(scenarios_sorted)\n",
    "if antibody == '9114':\n",
    "    top_set = scenarios_sorted[:5]+[tuple([\"white\"]*L)]\n",
    "    print('Optimal:',top_set[0])\n",
    "\n",
    "    # get best examples of other orderings\n",
    "    other_orderings = []\n",
    "    others = []\n",
    "    for i in range(10):\n",
    "        scenario_collapsed = list(OrderedDict.fromkeys(scenarios_sorted[i]))\n",
    "        if scenario_collapsed not in other_orderings:\n",
    "            other_orderings.append(scenario_collapsed)\n",
    "    for i in range(10,len(scenarios_sorted)):\n",
    "        scenario_collapsed = list(OrderedDict.fromkeys(scenarios_sorted[i]))\n",
    "        if scenario_collapsed not in other_orderings:\n",
    "            other_orderings.append(scenario_collapsed)\n",
    "            others.append(scenarios_sorted[i])\n",
    "        \n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + top_set + others)[::-1])\n",
    "    #print(keys)\n",
    "\n",
    "elif antibody == '6261':\n",
    "    top_set = scenarios_sorted[:18]\n",
    "    print('Optimal:',top_ten[0])        \n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + top_set)[::-1])\n",
    "    #print(keys)\n",
    "        \n",
    "likelihoods, err_likelihoods = [], []\n",
    "for k in keys:\n",
    "    if \"white\" in k:\n",
    "        likelihoods += [np.nan]\n",
    "        err_likelihoods += [np.nan]\n",
    "    elif \"random\" in k:\n",
    "        if np.median(proba_random_from_file[:,0]) == 0.0:\n",
    "            likelihoods += [np.nan]\n",
    "            err_likelihoods += [np.nan]\n",
    "        else:\n",
    "            likelihoods += [np.mean(np.mean(proba_random_from_file,axis=1),axis=0)]\n",
    "            err_likelihoods += [np.std(np.std(proba_random_from_file,axis=1,ddof=1),ddof=1) ]\n",
    "\n",
    "    elif np.mean(proba_from_file[k]) > 0.0:\n",
    "        likelihoods += [np.mean(proba_from_file[k])]\n",
    "        err_likelihoods += [np.std(proba_from_file[k],ddof=1)]\n",
    "    elif np.mean(proba_from_file[k]) == 0.0:\n",
    "        likelihoods += [np.nan]\n",
    "        err_likelihoods += [np.nan]\n",
    "        \n",
    "        \n",
    "likelihoods = np.array(likelihoods)\n",
    "err_likelihoods = np.array(err_likelihoods)\n",
    "print(likelihoods)\n",
    "    \n",
    "val = np.zeros((5*L, 5*len(keys)))\n",
    "for ii, key in enumerate(keys):\n",
    "    for jj, a in enumerate(key):\n",
    "        val[5*jj:5*(jj+1), 5*ii:5*(ii+1)] = {\"H1\":1, \"H3\":2, \"FluB\":3, \"H9\":4, \"\":0, \"white\":-1, \"random\":-2, \"mixed\":-2}[a]\n",
    "\n",
    "        \n",
    "if antibody == '6261':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.6,2))\n",
    "    gs = fig.add_gridspec(1,7)\n",
    "    ax0 = fig.add_subplot(gs[0,0:2])\n",
    "    ax = fig.add_subplot(gs[0,2:], sharey=ax0)\n",
    "\n",
    "elif antibody == '9114':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.8,2))\n",
    "    gs = fig.add_gridspec(1,5)\n",
    "    ax0 = fig.add_subplot(gs[0,0:2])\n",
    "    ax = fig.add_subplot(gs[0,2:], sharey=ax0)\n",
    "        \n",
    "# Turn off tick labels\n",
    "ax0.set_yticks([])\n",
    "ax0.set_xticks([])\n",
    "ax0.spines['top'].set_color('white')\n",
    "ax0.spines['bottom'].set_color('white')\n",
    "ax0.spines['right'].set_color('white')\n",
    "ax0.spines['left'].set_color('white')\n",
    "\n",
    "colorH1, colorH3, colorFluB, colorH9 = \"#E8735C\", \"#72C2A6\", \"#5482A7\", \"#663399\"\n",
    "\n",
    "pal = sns.color_palette()\n",
    "colors = [colorH1, 'white', 'xkcd:light grey', colorH1, colorH3, colorFluB, colorH9]\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "ax0.imshow(val.transpose(), interpolation='none', vmin=-2, vmax=4, cmap=cmap)\n",
    "mpl.rcParams['hatch.linewidth'] = 5 # previous pdf hatch linewidth\n",
    "mpl.rcParams['hatch.color'] = colorH3 # previous pdf hatch linewidth\n",
    "\n",
    "\n",
    "if antibody == \"9114\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 4\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH3]))\n",
    "    \n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 > 7\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorFluB]))\n",
    "\n",
    "if antibody == \"6261\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 5\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH9]))\n",
    "\n",
    "\n",
    "\n",
    "ax0.set_aspect('auto')\n",
    "for ii in range((val.shape[1]//5+1)):\n",
    "    #ax0.axhline(5*ii-1, color=\"white\", alpha=1, lw=1)\n",
    "    ax0.plot([0,5*L],[5*ii-.9,5*ii-.9],color=\"white\", alpha=1, lw=1)\n",
    "    ax0.plot([0,5*L],[5*ii-.1,5*ii-.1],color=\"white\", alpha=1, lw=1)\n",
    "\n",
    "ax0.set_ylim(-1, val.shape[1]+1)\n",
    "ax0.set_xlim([0,5*L])\n",
    "#ax0.set_xlabel(\"Context\")\n",
    "\n",
    "# max_loglik = np.nanmax(np.log(likelihoods))\n",
    "# min_loglik = np.nanmin(np.log(likelihoods))\n",
    "value_displayed = likelihoods #(-min_loglik + np.log(likelihoods))/(max_loglik - min_loglik)*0.8 + 0.1\n",
    "err_values = np.nan_to_num(err_likelihoods, 0)#/(max_loglik - min_loglik)*0.8, 0)\n",
    "\n",
    "#print(err_values)\n",
    "\n",
    "ax.barh(width=value_displayed+40,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5), height=4.5, left=-40, color='grey')\n",
    "        #color=[\"#7da6c2\", \"#c5e7ff\"]*(len(likelihoods)//2))\n",
    "#ax.invert_xaxis()\n",
    "ax.errorbar(x=value_displayed,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5),\n",
    "            xerr=err_values, color=\"k\", markersize=10, linestyle='', elinewidth=0.5, ecolor=\"k\")\n",
    "\n",
    "#ax.set_xlabel(\"Context log-likelihood\")\n",
    "#ax.set_xticklabels([])\n",
    "ax.set_ylim(-1, val.shape[1]+1)\n",
    "\n",
    "if antibody == \"9114\":\n",
    "    ax.set_xlim(0,2.2e8)\n",
    "    ax.set_xticks([0,1e8,2e8])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "elif antibody == \"6261\":\n",
    "    ax.set_xlim(0,2.4e5)\n",
    "    ax.set_xticks([0,1e5,2e5])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "plt.savefig(f\"images_supp/context_likelihood_{antibody}_{model}_complete.pdf\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal: ('H1', 'H1', 'H1', 'H1', 'H9', 'H9', 'H9', 'H9', 'H9', 'H9', 'H9')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-5849a3f5056c>:128: RuntimeWarning: invalid value encountered in log\n",
      "  max_loglik = np.nanmax(np.log(likelihoods))\n",
      "<ipython-input-14-5849a3f5056c>:128: RuntimeWarning: All-NaN slice encountered\n",
      "  max_loglik = np.nanmax(np.log(likelihoods))\n",
      "<ipython-input-14-5849a3f5056c>:129: RuntimeWarning: invalid value encountered in log\n",
      "  min_loglik = np.nanmin(np.log(likelihoods))\n",
      "<ipython-input-14-5849a3f5056c>:129: RuntimeWarning: All-NaN slice encountered\n",
      "  min_loglik = np.nanmin(np.log(likelihoods))\n",
      "<ipython-input-14-5849a3f5056c>:161: UserWarning: This figure was using constrained_layout==True, but that is incompatible with subplots_adjust and or tight_layout: setting constrained_layout==False. \n",
      "  plt.subplots_adjust(wspace=0.3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 160x200 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot for moderate/weak selection\n",
    "if model == 'strong':\n",
    "    sys.exit()\n",
    "    \n",
    "# select contexts we want to plot\n",
    "\n",
    "if antibody == '9114':\n",
    "    constant_scenarios = [tuple([\"mixed\"]*L),tuple([\"random\"]*L),\n",
    "                      tuple([\"H1\"]*L),tuple([\"H3\"]*L),tuple([\"FluB\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "elif antibody == '6261':\n",
    "    constant_scenarios = [tuple([\"mixed\"]*L),tuple([\"random\"]*L),\n",
    "                      tuple([\"H1\"]*L),tuple([\"H9\"]*L),\n",
    "                      tuple([\"white\"]*L)]\n",
    "\n",
    "    \n",
    "# sort other scenarios by likelihood\n",
    "scenarios_sorted = [k for k, v in sorted(proba_from_file.items(), key=lambda item: -np.log(np.mean([a for a in item[1] if a > 1e-80]))) if not all([l == k[0] for l in k])]\n",
    "\n",
    "if antibody == '9114':\n",
    "    top_set = scenarios_sorted[:5]+[tuple([\"white\"]*L)]\n",
    "    print('Optimal:',top_set[0])\n",
    "\n",
    "    # get best examples of other orderings\n",
    "    other_orderings = []\n",
    "    others = []\n",
    "    other_orderings.append(list(OrderedDict.fromkeys(scenarios_sorted[0])))\n",
    "    for i in range(len(scenarios_sorted)):\n",
    "        scenario_collapsed = list(OrderedDict.fromkeys(scenarios_sorted[i]))\n",
    "        if scenario_collapsed not in other_orderings:\n",
    "            other_orderings.append(scenario_collapsed)\n",
    "            others.append(scenarios_sorted[i])\n",
    "        \n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + top_set + others)[::-1])\n",
    "    print(len(keys))\n",
    "\n",
    "elif antibody == '6261':\n",
    "    top_set = scenarios_sorted[:18]\n",
    "    print('Optimal:',top_set[0])        \n",
    "\n",
    "    # combine all groups\n",
    "    keys = tuple((constant_scenarios + top_set)[::-1])\n",
    "    #print(keys)\n",
    "        \n",
    "likelihoods, err_likelihoods = [], []\n",
    "for k in keys:\n",
    "    if \"white\" in k:\n",
    "        likelihoods += [np.nan]\n",
    "        err_likelihoods += [np.nan]\n",
    "    elif \"random\" in k:\n",
    "        likelihoods += [np.mean(np.log(np.mean(proba_random_from_file,axis=1)),axis=0)]\n",
    "        err_likelihoods += [np.std(np.std(proba_random_from_file,axis=1,ddof=1)/np.mean(proba_random_from_file,axis=1),ddof=1) ]\n",
    "#         likelihoods += [np.log(np.mean(np.mean(proba_random,axis=1),axis=0))]\n",
    "#         err_likelihoods += [(np.std(np.std(proba_random,axis=1,ddof=1),axis=0,ddof=1))/np.mean(np.mean(proba_random,axis=1),axis=0)]\n",
    "\n",
    "    elif np.mean(proba_from_file[k]) > 0:\n",
    "        likelihoods += [np.log(np.mean([a for a in proba_from_file[k]]))]\n",
    "        err_likelihoods += [np.std([a for a in proba_from_file[k]],ddof=1)/np.mean([a for a in proba_from_file[k]])]\n",
    "\n",
    "likelihoods = np.array(likelihoods)\n",
    "err_likelihoods = np.array(err_likelihoods)\n",
    "        \n",
    "val = np.zeros((5*L, 5*len(keys)))\n",
    "for ii, key in enumerate(keys):\n",
    "    for jj, a in enumerate(key):\n",
    "        val[5*jj:5*(jj+1), 5*ii:5*(ii+1)] = {\"H1\":1, \"H3\":2, \"FluB\":3, \"H9\":4, \"\":0, \"white\":-1, \"random\":-2, \"mixed\":-2}[a]\n",
    "\n",
    "        \n",
    "if antibody == '6261':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.6,2))\n",
    "    gs = fig.add_gridspec(1,7)\n",
    "    ax0 = fig.add_subplot(gs[0,0:2])\n",
    "    ax = fig.add_subplot(gs[0,2:], sharey=ax0)\n",
    "\n",
    "elif antibody == '9114':        \n",
    "    fig = plt.figure(constrained_layout=True, figsize=(1.8,2))\n",
    "    gs = fig.add_gridspec(1,5)\n",
    "    ax0 = fig.add_subplot(gs[0,0:2])\n",
    "    ax = fig.add_subplot(gs[0,2:], sharey=ax0)\n",
    "        \n",
    "\n",
    "# Turn off tick labels\n",
    "ax0.set_yticks([])\n",
    "ax0.set_xticks([])\n",
    "ax0.spines['top'].set_color('white')\n",
    "ax0.spines['bottom'].set_color('white')\n",
    "ax0.spines['right'].set_color('white')\n",
    "ax0.spines['left'].set_color('white')\n",
    "\n",
    "colorH1, colorH3, colorFluB, colorH9 = \"#E8735C\", \"#72C2A6\", \"#5482A7\", \"#663399\"\n",
    "\n",
    "pal = sns.color_palette()\n",
    "colors = [colorH1, 'white', 'xkcd:light grey', colorH1, colorH3, colorFluB, colorH9]\n",
    "cmap = mpl.colors.ListedColormap(colors)\n",
    "ax0.imshow(val.transpose(), interpolation='none', vmin=-2, vmax=4, cmap=cmap)\n",
    "mpl.rcParams['hatch.linewidth'] = 5 # previous pdf hatch linewidth\n",
    "mpl.rcParams['hatch.color'] = colorH3 # previous pdf hatch linewidth\n",
    "\n",
    "\n",
    "if antibody == \"9114\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 4\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH3]))\n",
    "    \n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 > 7\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorFluB]))\n",
    "\n",
    "if antibody == \"6261\":\n",
    "    hashes = np.zeros(val.transpose().shape)\n",
    "    hashes = np.arange(0, val.shape[0]*val.shape[1]).reshape(val.shape).transpose()%11 < 5\n",
    "    ax0.imshow((val.transpose() == -2)*hashes, interpolation='none', cmap=mpl.colors.ListedColormap([\"#FFFFFF00\", colorH9]))\n",
    "\n",
    "\n",
    "\n",
    "ax0.set_aspect('auto')\n",
    "for ii in range((val.shape[1]//5+1)):\n",
    "    #ax0.axhline(5*ii-1, color=\"white\", alpha=1, lw=1)\n",
    "    ax0.plot([0,5*L],[5*ii-.9,5*ii-.9],color=\"white\", alpha=1, lw=1)\n",
    "    ax0.plot([0,5*L],[5*ii-.1,5*ii-.1],color=\"white\", alpha=1, lw=1)\n",
    "\n",
    "ax0.set_ylim(-1, val.shape[1]+1)\n",
    "ax0.set_xlim([0,5*L])\n",
    "#ax0.set_xlabel(\"Context\")\n",
    "\n",
    "max_loglik = np.nanmax(np.log(likelihoods))\n",
    "min_loglik = np.nanmin(np.log(likelihoods))\n",
    "value_displayed = likelihoods #(-min_loglik + np.log(likelihoods))/(max_loglik - min_loglik)*0.8 + 0.1\n",
    "err_values = np.nan_to_num(err_likelihoods, 0)#/(max_loglik - min_loglik)*0.8, 0)\n",
    "\n",
    "#print(err_values)\n",
    "\n",
    "ax.barh(width=value_displayed+40,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5), height=5., left=-40,\n",
    "        color=[\"#7da6c2\", \"#c5e7ff\"]*(len(likelihoods)//2))\n",
    "#ax.invert_xaxis()\n",
    "ax.errorbar(x=value_displayed,\n",
    "           y=np.arange(2.5, 5*len(likelihoods), 5),\n",
    "            xerr=err_values, color=\"k\", markersize=10, linestyle='', elinewidth=0.5, ecolor=\"#5b7c99\")\n",
    "\n",
    "#ax.set_xlabel(\"Context log-likelihood\")\n",
    "#ax.set_xticklabels([])\n",
    "ax.set_ylim(-1, val.shape[1]+1)\n",
    "\n",
    "if antibody == \"9114\" and model == 'moderate':\n",
    "    ax.set_xlim(-40,-10)\n",
    "    ax.set_xticks([-40,-30,-20,-10])\n",
    "    ax.set_xticklabels([])\n",
    "elif antibody == \"9114\" and model == 'weak' or model == 'weak2':\n",
    "    ax.set_xlim(-30,0)\n",
    "    ax.set_xticks([-30,-20,-10,0])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "elif antibody == \"6261\":\n",
    "    ax.set_xlim(-30,0)\n",
    "    ax.set_xticks([-30,-20,-10,0])\n",
    "    ax.set_xticklabels([])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "   \n",
    "plt.savefig(f\"images/context_likelihood_{antibody}_{model}_complete.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recalculate normalized probabilities for selected contexts (no bootstrapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized transition matrices \n",
    "pmut_unnormed = {}\n",
    "pmut_normed = {}\n",
    "for ag in tqdm(antigens+['mixed']):\n",
    "    pmut_unnormed[ag] = dok_matrix((2**L, 2**L), dtype=np.float64)\n",
    "    fitnesses = df[f\"{ag}_log10Kd\"].values.astype('float32')\n",
    "    \n",
    "    for s in sequences_int:\n",
    "        for t in reachable(s, L):\n",
    "            if model == 'strong':\n",
    "                pmut_unnormed[ag][s, t] = fixation_probability_binary(s,fitnesses[s],fitnesses[t])                \n",
    "            else:\n",
    "                pmut_unnormed[ag][s, t] = fixation_probability_moderate(fitnesses[s],fitnesses[t],N,gamma)\n",
    "\n",
    "    ### change format for something that can deal with multiplications\n",
    "    pmut_unnormed[ag].tocsr()\n",
    "    ### normalize the sparse matrix\n",
    "    pmut_normed[ag] = normalize(pmut_unnormed[ag], norm='l1', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the best and median random contexts\n",
    "random_means = np.mean(proba_random_from_file,axis=1)\n",
    "random_means_sorted = sorted(range(len(random_means)),key = lambda x: random_means[x])\n",
    "median_random_index = random_means_sorted[int(len(random_means)/2)+10] \n",
    "print(median_random_index) #,np.log(proba_random[median_random_index]))\n",
    "median_random = contexts_random_from_file[median_random_index]\n",
    "print(median_random,np.log(random_means[median_random_index]))\n",
    "\n",
    "\n",
    "\n",
    "plt.hist(np.log(np.mean(proba_random_from_file,axis=1)))\n",
    "plt.show()\n",
    "print(np.mean(np.log(proba_random_from_file)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define contexts of interest\n",
    "if antibody == \"9114\":\n",
    "    antigen_contexts = { \"optimal\": [\"H1\"]*5 + [\"H3\"]*8 + [\"FluB\"]* 3,\n",
    "                         \"H1alone\": [\"H1\"]*16,\n",
    "                         \"mixed\": [\"mixed\"]*16,\n",
    "                           \"random_median\": median_random}\n",
    "\n",
    "if antibody == \"6261\":\n",
    "    antigen_contexts = { \"optimal\": [\"H1\"]*4 + [\"H9\"]*7,\n",
    "                            \"H1alone\": [\"H1\"]*11,  \n",
    "                         \"H9alone\": [\"H9\"]*11,\n",
    "                         \"mixed\": [\"mixed\"]*11,\n",
    "                           \"random_median\": median_random}\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutation order (Figure 5I,J, Figure 5 -- Figure Supplement 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "for ac in tqdm(antigen_contexts):\n",
    "    ## precompute the transition probability matrix to every power\n",
    "    pmut_power = {}\n",
    "    for i in range(L):\n",
    "        pmut_power[i] = pmut_normed[antigen_contexts[ac][i]]**i\n",
    "\n",
    "    ## compute the matrix that force the mutation to be mut\n",
    "    force_mut = {}\n",
    "    for mut in range(L):\n",
    "        for i in range(L):\n",
    "            force_mut[(i,mut)] = dok_matrix((2**L, 2**L), dtype=np.float64)\n",
    "        \n",
    "        for s in sequences_int[:-1]:\n",
    "            nb_mut = nb_mutation(s)\n",
    "            t = mutation(s, mut,L)\n",
    "            force_mut[(nb_mut,mut)][s, t] = pmut_normed[antigen_contexts[ac][nb_mut]][s, t]\n",
    "\n",
    "    ## compute probabilities\n",
    "    proba = np.zeros((L, L))\n",
    "    for mut in range(L):\n",
    "        for t in range(1, L+1):\n",
    "            proba[mut, t-1] = (pmut_power[t-1] @ force_mut[(t-1,mut)] @ pmut_power[L - t])[0, 2**L - 1]\n",
    "\n",
    "    ## print results to file\n",
    "    if antibody == '9114':\n",
    "        proba_df = pd.DataFrame(proba,columns=\n",
    "                        [\"Order 1\",\"Order 2\",\"Order 3\",\"Order 4\",\"Order 5\",\"Order 6\",\n",
    "                         \"Order 7\",\"Order 8\",\"Order 9\",\"Order 10\",\"Order 11\",\"Order 12\",\n",
    "                        \"Order 13\",\"Order 14\",\"Order 15\",\"Order 16\"])\n",
    "        proba_df['Mutation'] = [\"Mut 1\",\"Mut 2\",\"Mut 3\",\"Mut 4\",\"Mut 5\",\"Mut 6\",\n",
    "                       \"Mut 7\",\"Mut 8\",\"Mut 9\",\"Mut 10\",\"Mut 11\",\n",
    "                       \"Mut 12\",\"Mut 13\",\"Mut 14\",\"Mut 15\",\"Mut 16\"] \n",
    "        proba_df.to_csv(\"data/9114_probability_\"+str(ac)+\"_\"+model+\".csv\",index=False)\n",
    "    \n",
    "    elif antibody == '6261':\n",
    "        proba_df = pd.DataFrame(proba,columns=\n",
    "                        [\"Order 1\",\"Order 2\",\"Order 3\",\"Order 4\",\"Order 5\",\"Order 6\",\n",
    "                         \"Order 7\",\"Order 8\",\"Order 9\",\"Order 10\",\"Order 11\"])\n",
    "        proba_df['Mutation'] = [\"Mut 1\",\"Mut 2\",\"Mut 3\",\"Mut 4\",\"Mut 5\",\"Mut 6\",\n",
    "                       \"Mut 7\",\"Mut 8\",\"Mut 9\",\"Mut 10\",\"Mut 11\"] \n",
    "        proba_df.to_csv(\"data/6261_probability_\"+str(ac)+\"_\"+model+\".csv\",index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5 -- Figure Supplement 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### Plot probabilty of each variant in optimal context ####\n",
    "  \n",
    "\n",
    "for context in [\"optimal\"]:\n",
    "    print(context)\n",
    "    antigen_context = antigen_contexts[context]\n",
    "    ## Compute the probability of belonging to the path for each variant\n",
    "    # if strong selection, use non-normalized, otherwise normalized\n",
    "    if model == 'strong':\n",
    "        A = {0: pmut_unnormed[antigen_context[0]]**0}\n",
    "        B = {0: pmut_unnormed[antigen_context[0]]**0}\n",
    "        for ii in range(1, L+1):\n",
    "            A[ii] = A[ii-1]@pmut_unnormed[antigen_context[ii-1]]\n",
    "            B[ii] = pmut_unnormed[antigen_context[ii-1]]@B[ii-1]\n",
    "    else:\n",
    "        A = {0: pmut_normed[antigen_context[0]]**0}\n",
    "        B = {0: pmut_normed[antigen_context[0]]**0}\n",
    "        for ii in range(1, L+1):\n",
    "            A[ii] = A[ii-1]@pmut_normed[antigen_context[ii-1]]\n",
    "            B[ii] = pmut_normed[antigen_context[ii-1]]@B[ii-1]\n",
    "        \n",
    "\n",
    "    proba = np.zeros(2**L)\n",
    "    norm = defaultdict(int)\n",
    "    for v in tqdm(sequences_int):\n",
    "        if v != 0 and v != 2**L - 1:\n",
    "            n = nb_mutation(v)\n",
    "            proba[v] = (A[n])[0, v] * B[L - n][v, 2**L-1]\n",
    "            norm[n] += 1\n",
    "    for v in sequences_int:\n",
    "        if model == 'strong':\n",
    "            # normalize explicitly\n",
    "            proba[v] = proba[v] * norm[nb_mutation(v)] /math.factorial(L)\n",
    "        else:\n",
    "            proba[v] = proba[v] * norm[nb_mutation(v)]\n",
    "    proba[0] = 1\n",
    "    proba[2**L-1] = 1\n",
    "    \n",
    "    #df[\"proba_path\"] = proba \n",
    "\n",
    "    mpl.rcParams['figure.dpi'] = 200\n",
    "\n",
    "    print(np.nanmin(proba),np.nanmax(proba))\n",
    "\n",
    "    indices = np.where(proba > 0.0)[0]\n",
    "\n",
    "    if model != 'strong':\n",
    "        probas_for_plot = np.log10(proba[indices])\n",
    "    too_low = np.where(probas_for_plot < -50)[0]\n",
    "    probas_for_plot[too_low] = -50\n",
    "    \n",
    "    print(len(np.where(probas_for_plot > 0)[0]))\n",
    "                         \n",
    "    fig,ax = plt.subplots(figsize=(2,2))\n",
    "    ax.tick_params(pad=1)\n",
    "    plt.hist(probas_for_plot,bins=100,color=cm.inferno_r(0.2))\n",
    "    #plt.yscale('log')\n",
    "    plt.plot([0,0],[0,10000],'k--',linewidth=0.5)\n",
    "    plt.ylim([0,10000])\n",
    "    #plt.xlim(-102,0)\n",
    "    plt.xticks([-50,-25,0,],['<-50','-25','0'])\n",
    "    #plt.yticks([0,2000,4000,6000],['0','2000','4000','6000'])\n",
    "    plt.xlabel(r'$\\log_{10}\\left(\\dfrac{P_{optimal}}{P_{neutral}}\\right)$',labelpad=1)\n",
    "    plt.ylabel('Variant count',labelpad=1)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images_supp/variantdist_'+antibody+'_'+context+'_'+model+'.pdf')\n",
    "    plt.show()\n",
    "    #df\n",
    "\n",
    "    df_fdl = pd.read_csv(\"../Figure2/20210430_fdl_9114.csv\", dtype={\"variant\":\"str\"})\n",
    "    df_fdl[\"variant_int\"] = df_fdl.variant.apply(lambda x: int(x, 2))\n",
    "    df_fdl = df_fdl.set_index(\"variant_int\").reindex(range(0, 2**L)).reset_index()\n",
    "\n",
    "    df_fdl[\"path_prob\"] = proba\n",
    "\n",
    "    df_fdl = df_fdl.sort_values(by=[\"path_prob\"])\n",
    "\n",
    "    minval = 1.0\n",
    "    cmap = plt.get_cmap('inferno_r')\n",
    "    new_cmap = truncate_colormap(cmap, 0.1,1)\n",
    "\n",
    "    plt.figure(figsize=(3,3)) #plt.subplots(2, 1, figsize=(10, 10), gridspec_kw={'height_ratios': [4, 1]})\n",
    "    ax = plt.subplot(111)\n",
    "    ax.scatter(x=-1.0*df_fdl.fdl_x, y=-1.0*df_fdl.fdl_y,\n",
    "           s=.8, color =cmap(0.0), alpha=1)\n",
    "    sc = ax.scatter(x=-1.0*df_fdl.loc[df_fdl['path_prob'] > minval,'fdl_x'], y=-1.0*df_fdl.loc[df_fdl['path_prob'] > minval,'fdl_y'],\n",
    "           s=.8, c=np.log(df_fdl.loc[df_fdl['path_prob'] > minval,'path_prob']),\n",
    "           cmap=new_cmap,vmin=minval,alpha=1)\n",
    "    cbar = plt.colorbar(sc,fraction=0.02,ticks=[1,3,5])\n",
    "    cbar.ax.set_yticklabels(['1','$10^3$','$10^5$'])\n",
    "    cbar.ax.set_ylabel(r'$\\dfrac{P_{optimal}}{P_{neutral}}$',rotation='horizontal',labelpad=15)\n",
    "    #plt.clim(-4,4)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "\n",
    "    #ax.get_legend().remove()\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images_supp/landscape_paths_'+antibody+'_'+context+'_'+model+'.png',dpi=600)\n",
    "    plt.show()\n",
    "    \n",
    "#     sys.exit()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5G,H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directed weighted graph\n",
    "\n",
    "\n",
    "# store fitnesses as dict\n",
    "fitnesses = {}\n",
    "for a in antigens+['mixed']:\n",
    "    fitnesses[a] = (df.set_index(\"variant_int\")[f\"{a}_log10Kd\"]).to_dict()\n",
    "\n",
    "df[\"nb_mutation\"] = df.variant_int.apply(nb_mutation)\n",
    "\n",
    "# choose number of best paths to store\n",
    "num_best_paths = 25\n",
    "best_paths = {}\n",
    "\n",
    "#for ac in tqdm(antigen_contexts):\n",
    "for ac in tqdm(['random_median']):\n",
    "        \n",
    "    # (re) create the graph with networkx (as a directed graph)\n",
    "    G = nx.DiGraph()\n",
    "    G.add_nodes_from(sequences_int)\n",
    "    G.add_weighted_edges_from([(s, t,  ## source, target\n",
    "                                -np.log(1e-100 + pmut_unnormed[antigen_contexts[ac][nb_mutation(s)]][s, t])  # weight\n",
    "                               ) \n",
    "                      for s in sequences_int\n",
    "                      for t in reachable(s, L)])\n",
    "    \n",
    "    # compute the k shortest paths, for which  -log(p) is smallest => max likelihood\n",
    "    best_paths[ac] = np.empty((num_best_paths,L+1),dtype=int)\n",
    "    i = 0\n",
    "    for path in k_shortest_paths(G, 0, 2**L-1,num_best_paths,weight='weight'):\n",
    "        best_paths[ac][i] = path\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get Kds and delta Kds for 9114 best paths\n",
    "num_to_use = 25\n",
    "\n",
    "best_path_mean_Kds_H1 = {}\n",
    "best_path_mean_Kds_H3 = {}\n",
    "best_path_mean_Kds_B = {}\n",
    "best_path_std_Kds_H1 = {}\n",
    "best_path_std_Kds_H3 = {}\n",
    "best_path_std_Kds_B = {}\n",
    "\n",
    "best_paths_Kds_H1 = {}\n",
    "best_paths_Kds_H3 = {}\n",
    "best_paths_Kds_B = {}\n",
    "best_paths_err_Kds_H1 = {}\n",
    "best_paths_err_Kds_H3 = {}\n",
    "best_paths_err_Kds_B = {}\n",
    "\n",
    "\n",
    "for ac in antigen_contexts:\n",
    "    best_path_means_H1 = np.empty((num_to_use,L+1),dtype=float)\n",
    "    best_path_stderr_H1 = np.empty((num_to_use,L+1),dtype=float)\n",
    "    best_path_means_H3 = np.empty((num_to_use,L+1),dtype=float)\n",
    "    best_path_stderr_H3 = np.empty((num_to_use,L+1),dtype=float)\n",
    "    best_path_means_B = np.empty((num_to_use,L+1),dtype=float)\n",
    "    best_path_stderr_B = np.empty((num_to_use,L+1),dtype=float)\n",
    "\n",
    "    for i in range(num_to_use):\n",
    "        best_path_means_H1[i,:] = [df.loc[best_paths[ac][i,n]][\"H1_log10Kd\"] for n in range(L+1)]\n",
    "        best_path_stderr_H1[i,:] = [df.loc[best_paths[ac][i,n]][\"H1_stelog10Kd\"] for n in range(L+1)]\n",
    "        best_path_means_H3[i,:] = [df.loc[best_paths[ac][i,n]][\"H3_log10Kd\"] for n in range(L+1)]\n",
    "        best_path_stderr_H3[i,:] = [df.loc[best_paths[ac][i,n]][\"H3_stelog10Kd\"] for n in range(L+1)]\n",
    "        best_path_means_B[i,:] = [df.loc[best_paths[ac][i,n]][\"FluB_log10Kd\"] for n in range(L+1)]\n",
    "        best_path_stderr_B[i,:] = [df.loc[best_paths[ac][i,n]][\"FluB_stelog10Kd\"] for n in range(L+1)]\n",
    "    \n",
    "    best_paths_Kds_H1[ac] = best_path_means_H1\n",
    "    best_paths_err_Kds_H1[ac] = best_path_stderr_H1\n",
    "    best_paths_Kds_H3[ac] = best_path_means_H3\n",
    "    best_paths_err_Kds_H3[ac] = best_path_stderr_H3\n",
    "    best_paths_Kds_B[ac] = best_path_means_B\n",
    "    best_paths_err_Kds_B[ac] = best_path_stderr_B\n",
    "    \n",
    "    best_path_mean_Kds_H1[ac] = np.nanmean(best_path_means_H1,axis=0)\n",
    "    best_path_mean_Kds_H3[ac] = np.nanmean(best_path_means_H3,axis=0)\n",
    "    best_path_mean_Kds_B[ac] = np.nanmean(best_path_means_B,axis=0)\n",
    "    \n",
    "    best_path_std_Kds_H1[ac] = np.std(best_path_means_H1,axis=0)\n",
    "    best_path_std_Kds_H3[ac] = np.std(best_path_means_H3,axis=0)\n",
    "    best_path_std_Kds_B[ac] = np.std(best_path_means_B,axis=0)\n",
    "\n",
    "    \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for context in antigen_contexts:\n",
    "    print(antigen_contexts[context])\n",
    "    fig,ax = plt.subplots(figsize=(2.2,0.85))\n",
    "    ax.tick_params(pad=1)\n",
    "    for i in range(num_best_paths):\n",
    "        plt.errorbar(x=range(L+1),y=best_paths_Kds_B[context][i],yerr=best_paths_err_Kds_B[context][i],\n",
    "                 color=colorFluB,alpha=0.2,linewidth=0.5)\n",
    "        plt.errorbar(x=range(L+1),y=best_paths_Kds_H3[context][i],yerr=best_paths_err_Kds_H3[context][i],\n",
    "                 color=colorH3,alpha=0.2,linewidth=0.5)\n",
    "        plt.errorbar(x=range(L+1),y=best_paths_Kds_H1[context][i],yerr=best_paths_err_Kds_H1[context][i],\n",
    "                 color=colorH1,alpha=0.2,linewidth=0.5)\n",
    "        \n",
    "        if context == \"mixed\":\n",
    "            plt.errorbar(x=range(L+1),y=np.mean([best_paths_Kds_B[context][i],best_paths_Kds_H3[context][i],best_paths_Kds_H1[context][i]],axis=0),\n",
    "                color='k',alpha=0.2,linewidth=0.5)\n",
    "            \n",
    "    #plt.xlabel('Number of mutations')\n",
    "    plt.ylabel(f\"$-logK_D$\",labelpad=0)\n",
    "    #plt.xticks(np.arange(0,18,2),[str(x) for x in np.arange(0,18,2)])\n",
    "    plt.yticks([6,8,10],['6','8','10'])\n",
    "    plt.ylim([5.5,10.3])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/average_paths_'+antibody+'_'+context+'_'+model+'.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot Kds and delta Kds for 6261 best paths\n",
    "num_to_use = num_best_paths\n",
    "\n",
    "\n",
    "best_paths_Kds_H1 = {}\n",
    "best_paths_Kds_H9 = {}\n",
    "best_paths_err_Kds_H1 = {}\n",
    "best_paths_err_Kds_H9 = {}\n",
    "\n",
    "\n",
    "#for ac in antigen_contexts:\n",
    "for ac in ['random_median']:\n",
    "    best_paths_Kds_H1[ac] = []\n",
    "    best_paths_err_Kds_H1[ac] = []\n",
    "    best_paths_Kds_H9[ac] = []\n",
    "    best_paths_err_Kds_H9[ac] = []\n",
    "    \n",
    "    for i in range(num_to_use):\n",
    "        best_paths_Kds_H1[ac].append([df.loc[best_paths[ac][i,n]][\"H1_log10Kd\"] for n in range(L+1)])\n",
    "        best_paths_err_Kds_H1[ac].append([df.loc[best_paths[ac][i,n]][\"H1_stelog10Kd\"] for n in range(L+1)])\n",
    "        best_paths_Kds_H9[ac].append([df.loc[best_paths[ac][i,n]][\"H9_log10Kd\"] for n in range(L+1)])\n",
    "        best_paths_err_Kds_H9[ac].append([df.loc[best_paths[ac][i,n]][\"H1_stelog10Kd\"] for n in range(L+1)])\n",
    "\n",
    "\n",
    "\n",
    "#for context in antigen_contexts:\n",
    "for context in ['random_median']:\n",
    "    print(antigen_contexts[context])\n",
    "    fig,ax = plt.subplots(figsize=(1.7,0.85))\n",
    "    ax.tick_params(pad=1)\n",
    "    for i in range(num_best_paths):\n",
    "        plt.errorbar(x=range(L+1),y=best_paths_Kds_H1[context][i],yerr=best_paths_err_Kds_H1[context][i],\n",
    "                 color=colorH1,alpha=0.2,linewidth=0.5)\n",
    "        plt.errorbar(x=range(L+1),y=best_paths_Kds_H9[context][i],yerr=best_paths_err_Kds_H9[context][i],\n",
    "                 color=colorH9,alpha=0.2,linewidth=0.5)\n",
    "        \n",
    "        if context == \"mixed\":\n",
    "            plt.errorbar(x=range(L+1),y=np.mean([best_paths_Kds_H1[context][i],best_paths_Kds_H9[context][i]],axis=0),\n",
    "                color='k',alpha=0.2,linewidth=0.5)\n",
    "            \n",
    "    #plt.xlabel('Number of mutations')\n",
    "    plt.ylabel(f\"$-logK_D$\",labelpad=0)\n",
    "    plt.yticks([7,8,9,10],['7','8','9','10'])\n",
    "    plt.ylim([6.5,10.5])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('images/average_paths_'+antibody+'_'+context+'_'+model+'.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
